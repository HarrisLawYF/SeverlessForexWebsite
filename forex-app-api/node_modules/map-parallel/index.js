"use strict";

const Worker = require("tiny-worker");

const mapParallel = (arr, chunkSize, cb, base) => {
  // "packages" in this context like Apple's, Grand Central Dispatch
  // "work packages", albeit using Data Parallelism instead of Task Parallelism
  return new Promise((resolve, reject) => {
    const packages = _chunkify(arr, chunkSize).map((chunk) =>
      _processInWorker(chunk, cb, base));

    Promise.all(packages).then((result) => {
      resolve(result.reduce(_flattenArr));
    }).catch(reject);
  });
}

const _processInWorker = (chunk, cb, base) => {
  return new Promise((resolve, reject) => {
    const worker = new Worker(() => {
      self.onmessage = (ev) => {
        let results = ev.data.chunk.reduce((arr, item) => {
          return [...arr, ...[eval(ev.data.cb)(item, ev.data.base)]];
        }, [])

        postMessage(results);
      };
    });

    worker.onmessage = (ev) => {
      worker.terminate();
      resolve(ev.data);
    };

    worker.onerror = (err) => {
      worker.terminate();
      reject(err);
    };

    worker.postMessage({
      base: base,
      chunk: chunk,
      cb: cb.toString()
    });
  });
}

const _chunkify = (arr, n) => {
  if (!Array.isArray(arr)) throw new Error("Expected an Array");

  let rest = arr.length % n;
  let restUsed = rest;
  let partLength = Math.floor(arr.length / n);
  let result = [];

  for (let i = 0; i < arr.length; i += partLength) {
    let end = partLength + i;
    let add = false;

    if (rest !== 0 && restUsed) {
      end++;
      restUsed--;
      add = true;
    }

    result.push(arr.slice(i, end));

    if(add) i++;
  }

  return result;
}

const _flattenArr = (arr, chunk) => {
  return [...arr, ...chunk];
}

module.exports.map = mapParallel;
module.exports._chunkify = _chunkify;
